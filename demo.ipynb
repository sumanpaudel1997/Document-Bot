{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_anthropic import ChatAnthropic\n",
    "# import os\n",
    "\n",
    "# anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0.2, max_tokens=1024, anthropic_api_key=anthropic_api_key)\n",
    "\n",
    "# # claude-3-sonnet-20240229\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import google.generativeai as genai\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/embedding-001\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "api_key=os.environ.get(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = genai.GenerativeModel(model_name = \"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Pros of Python:**\n",
      "\n",
      "* **Readability and simplicity:** Python's syntax is designed to be clear and concise, making it easy to read and understand, even for beginners.\n",
      "* **Extensive libraries:** Python has a vast ecosystem of libraries and frameworks, providing pre-built functionality for various tasks, such as data science, machine learning, web development, and more.\n",
      "* **Flexibility and versatility:** Python is a general-purpose language suitable for developing a wide range of applications, from small scripts to complex enterprise systems.\n",
      "* **Cross-platform support:** Python can run on multiple operating systems, including Windows, macOS, Linux, and Unix, without requiring platform-specific recompilation.\n",
      "* **Beginner-friendly:** Python's simplicity and ease of learning make it an excellent choice for beginners who are new to programming.\n",
      "* **Strong community support:** Python has a large and active community, providing resources, documentation, and support to developers.\n",
      "\n",
      "**Cons of Python:**\n",
      "\n",
      "* **Speed and performance:** Python is an interpreted language, which means it is slower than compiled languages like C or Java, especially for computationally intensive tasks.\n",
      "* **Memory management:** Python's automatic memory management can lead to performance overhead and memory leaks if not managed properly.\n",
      "* **Lack of type checking:** Python is a dynamically typed language, which can result in runtime errors related to data types and variable assignments.\n",
      "* **GIL (Global Interpreter Lock):** Python uses a GIL to ensure thread safety, but this can limit parallelism and performance in multithreaded applications.\n",
      "* **Package management:** While Python has a large number of libraries, managing dependencies and package updates can be complex and time-consuming.\n",
      "* **Debugging:** Python's dynamic nature can make it challenging to debug errors, as the behavior of variables and objects can change at runtime.\n"
     ]
    }
   ],
   "source": [
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=api_key)\n",
    "print(\n",
    "    llm.invoke(\n",
    "        \"What are some of the pros and cons of Python as a programming language?\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How much is 2+2?\n",
      "\n",
      "Answer: 4\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "question = \"How much is 2+2?\"\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"spark.pdf\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can let you visualize test results.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This context does not mention anything about PySpark, so I cannot answer this question from the provided context.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"what is PySpark\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
